{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FAST-BERT SENTIMENT ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import sagemaker\n",
    "from pathlib import Path\n",
    "from sagemaker.predictor import json_serializer, csv_serializer\n",
    "import json\n",
    "\n",
    "# Get the sagemaker execution role and the session\n",
    "role = sagemaker.get_execution_role()\n",
    "session = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-fast-bert/sentiment/input/data/train.csv to ./train.csv\n",
      "download: s3://sagemaker-fast-bert/sentiment/input/data/val.csv to ./val.csv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp s3://sagemaker-fast-bert/sentiment/input/data/train.csv .\n",
    "!aws s3 cp s3://sagemaker-fast-bert/sentiment/input/data/val.csv ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set comprises 134603 samples.\n",
      "Validation set comprises 8973 samples.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15001</th>\n",
       "      <td>Friendly staff and quick service</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16134</th>\n",
       "      <td>Great food an service.</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137459</th>\n",
       "      <td>Great service and staff</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11891</th>\n",
       "      <td>No service</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8761</th>\n",
       "      <td>Servi was gud</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     text label\n",
       "15001   Friendly staff and quick service    pos\n",
       "16134             Great food an service.    pos\n",
       "137459           Great service and staff    pos\n",
       "11891                         No service    neg\n",
       "8761                       Servi was gud    pos"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('train.csv', index_col=0)\n",
    "val = pd.read_csv('val.csv', index_col=0)\n",
    "\n",
    "print('Train set comprises {} samples.'.format(len(train)))\n",
    "print('Validation set comprises {} samples.'.format(len(val))) \n",
    "train.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix',\n",
       "   'S3Uri': 's3://sagemaker-fast-bert/sentiment/input/data/',\n",
       "   'S3DataDistributionType': 'FullyReplicated'}},\n",
       " 'ContentType': 'text/csv'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = ['neg', 'pos', 'mixed']\n",
    "\n",
    "with open('labels.csv', 'w') as csvfile:\n",
    "    for label in labels:\n",
    "        csvfile.write(label + '\\n')\n",
    "        \n",
    "# Prefix for S3 bucket for configurations, input and output\n",
    "prefix_input = 'sentiment/input/data'\n",
    "prefix_output = 'sentiment/output'\n",
    "prefix_config = 'sentiment/input/data/config'\n",
    "\n",
    "# S3 bucket name\n",
    "bucket = 'sagemaker-fast-bert'\n",
    "        \n",
    "fObj = open(\"labels.csv\", 'rb')\n",
    "key = os.path.join(prefix_input, 'labels.csv')\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(key).upload_fileobj(fObj)\n",
    "\n",
    "# location for train.csv, val.csv, and labels.csv\n",
    "s3_input = \"s3://{}/{}/\".format(bucket, prefix_input)\n",
    "data_input = sagemaker.session.s3_input(s3_input, distribution='FullyReplicated', \n",
    "                             content_type='text/csv', s3_data_type='S3Prefix')\n",
    "\n",
    "# output path for storage of model\n",
    "output_path = \"s3://{}/{}\".format(bucket, prefix_output)\n",
    "\n",
    "data_input.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'944828514909.dkr.ecr.us-east-1.amazonaws.com/sagemaker-bert-session:1.0-gpu-py36'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparameters = {\n",
    "    \"epochs\": 1,\n",
    "    \"lr\": 4e-5,\n",
    "    \"max_seq_length\": 256,\n",
    "    \"train_batch_size\": 8,\n",
    "    \"lr_schedule\": \"warmup_cosine\",\n",
    "    \"warmup_steps\": 500,\n",
    "    \"optimizer_type\": \"adamw\"\n",
    "}\n",
    "\n",
    "training_config = {\n",
    "    \"run_text\": \"sentiment classification\",\n",
    "    \"finetuned_model\": None,\n",
    "    \"do_lower_case\": True,\n",
    "    \"train_file\": \"train.csv\",\n",
    "    \"val_file\": \"val.csv\",\n",
    "    \"label_file\": \"labels.csv\",\n",
    "    \"text_col\": \"text\",\n",
    "    \"label_col\": \"label\",\n",
    "    \"multi_label\": False,\n",
    "    \"grad_accumulation_steps\": \"8\",\n",
    "    \"fp16_opt_level\": \"O2\",\n",
    "    \"fp16\": False,\n",
    "    \"model_type\": \"bert\",\n",
    "    \"model_name\": \"bert-base-uncased\",\n",
    "    \"logging_steps\": \"300\"\n",
    "}\n",
    "\n",
    "# save training config\n",
    "with open('training_config.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(training_config, f)\n",
    "\n",
    "fObj = open(\"training_config.json\", 'rb')\n",
    "key = os.path.join(prefix_config, 'training_config.json')\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(key).upload_fileobj(fObj)\n",
    "\n",
    "# Construct the ECR image location \n",
    "account = session.boto_session.client('sts').get_caller_identity()['Account']\n",
    "region = session.boto_session.region_name\n",
    "image = \"{}.dkr.ecr.{}.amazonaws.com/sagemaker-bert-session:1.0-gpu-py36\".format(account, region)\n",
    "\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-24 15:23:27 Starting - Starting the training job...\n",
      "2019-10-24 15:23:28 Starting - Launching requested ML instances......\n",
      "2019-10-24 15:24:35 Starting - Preparing the instances for training......\n",
      "2019-10-24 15:25:53 Downloading - Downloading input data\n",
      "2019-10-24 15:25:53 Training - Downloading the training image.................\u001b[31mStarting the training.\u001b[0m\n",
      "\u001b[31m/opt/ml/input/data/training/config/training_config.json\u001b[0m\n",
      "\u001b[31m{'run_text': 'sentiment', 'finetuned_model': None, 'do_lower_case': True, 'train_file': 'train.csv', 'val_file': 'val.csv', 'label_file': 'labels.csv', 'text_col': 'text', 'label_col': 'label', 'multi_label': False, 'grad_accumulation_steps': '8', 'fp16_opt_level': 'O2', 'fp16': False, 'model_type': 'bert', 'model_name': 'bert-base-uncased', 'logging_steps': '300'}\u001b[0m\n",
      "\u001b[31m{'train_batch_size': '8', 'warmup_steps': '500', 'lr': '4e-05', 'max_seq_length': '256', 'optimizer_type': 'adamw', 'lr_schedule': 'warmup_cosine', 'epochs': '1'}\u001b[0m\n",
      "\u001b[31m10/24/2019 15:28:35 - INFO - root -   model path used /opt/ml/code/pretrained_models/bert-base-uncased\u001b[0m\n",
      "\u001b[31m10/24/2019 15:28:35 - INFO - root -   finetuned model not available - loading standard pretrained model\u001b[0m\n",
      "\u001b[31m10/24/2019 15:28:35 - INFO - transformers.tokenization_utils -   Model name '/opt/ml/code/pretrained_models/bert-base-uncased' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased). Assuming '/opt/ml/code/pretrained_models/bert-base-uncased' is a path or url to a directory containing tokenizer files.\u001b[0m\n",
      "\u001b[31m10/24/2019 15:28:35 - INFO - transformers.tokenization_utils -   Didn't find file /opt/ml/code/pretrained_models/bert-base-uncased/added_tokens.json. We won't load it.\u001b[0m\n",
      "\u001b[31m10/24/2019 15:28:35 - INFO - transformers.tokenization_utils -   Didn't find file /opt/ml/code/pretrained_models/bert-base-uncased/special_tokens_map.json. We won't load it.\u001b[0m\n",
      "\u001b[31m10/24/2019 15:28:35 - INFO - transformers.tokenization_utils -   Didn't find file /opt/ml/code/pretrained_models/bert-base-uncased/tokenizer_config.json. We won't load it.\u001b[0m\n",
      "\u001b[31m10/24/2019 15:28:35 - INFO - transformers.tokenization_utils -   loading file /opt/ml/code/pretrained_models/bert-base-uncased/vocab.txt\u001b[0m\n",
      "\u001b[31m10/24/2019 15:28:35 - INFO - transformers.tokenization_utils -   loading file None\u001b[0m\n",
      "\u001b[31m10/24/2019 15:28:35 - INFO - transformers.tokenization_utils -   loading file None\u001b[0m\n",
      "\u001b[31m10/24/2019 15:28:35 - INFO - transformers.tokenization_utils -   loading file None\u001b[0m\n",
      "\u001b[31m10/24/2019 15:28:35 - INFO - root -   Number of GPUs: 1\u001b[0m\n",
      "\u001b[31m10/24/2019 15:28:35 - INFO - root -   label columns: label\u001b[0m\n",
      "\u001b[31m10/24/2019 15:28:39 - INFO - root -   Writing example 0 of 134603\u001b[0m\n",
      "\u001b[31m10/24/2019 15:28:43 - INFO - root -   Writing example 10000 of 134603\u001b[0m\n",
      "\n",
      "2019-10-24 15:28:32 Training - Training image download completed. Training in progress.\u001b[31m10/24/2019 15:28:48 - INFO - root -   Writing example 20000 of 134603\u001b[0m\n",
      "\u001b[31m10/24/2019 15:28:52 - INFO - root -   Writing example 30000 of 134603\u001b[0m\n",
      "\u001b[31m10/24/2019 15:28:57 - INFO - root -   Writing example 40000 of 134603\u001b[0m\n",
      "\u001b[31m10/24/2019 15:29:01 - INFO - root -   Writing example 50000 of 134603\u001b[0m\n",
      "\u001b[31m10/24/2019 15:29:06 - INFO - root -   Writing example 60000 of 134603\u001b[0m\n",
      "\u001b[31m10/24/2019 15:29:10 - INFO - root -   Writing example 70000 of 134603\u001b[0m\n",
      "\u001b[31m10/24/2019 15:29:15 - INFO - root -   Writing example 80000 of 134603\u001b[0m\n",
      "\u001b[31m10/24/2019 15:29:19 - INFO - root -   Writing example 90000 of 134603\u001b[0m\n",
      "\u001b[31m10/24/2019 15:29:24 - INFO - root -   Writing example 100000 of 134603\u001b[0m\n",
      "\u001b[31m10/24/2019 15:29:29 - INFO - root -   Writing example 110000 of 134603\u001b[0m\n",
      "\u001b[31m10/24/2019 15:29:33 - INFO - root -   Writing example 120000 of 134603\u001b[0m\n",
      "\u001b[31m10/24/2019 15:29:38 - INFO - root -   Writing example 130000 of 134603\u001b[0m\n",
      "\u001b[31m10/24/2019 15:29:40 - INFO - root -   Saving features into cached file /opt/ml/input/data/training/cache/cached_bert_train_multi_class_256\u001b[0m\n",
      "\u001b[31m10/24/2019 15:30:34 - INFO - root -   Writing example 0 of 8973\u001b[0m\n",
      "\u001b[31m10/24/2019 15:30:37 - INFO - root -   Saving features into cached file /opt/ml/input/data/training/cache/cached_bert_dev_multi_class_256\u001b[0m\n",
      "\u001b[31m10/24/2019 15:30:41 - INFO - root -   databunch labels: 3\u001b[0m\n",
      "\u001b[31m10/24/2019 15:30:41 - INFO - root -   multilabel: False, multilabel type: <class 'bool'>\u001b[0m\n",
      "\u001b[31m10/24/2019 15:30:41 - INFO - transformers.configuration_utils -   loading configuration file /opt/ml/code/pretrained_models/bert-base-uncased/config.json\u001b[0m\n",
      "\u001b[31m10/24/2019 15:30:41 - INFO - transformers.configuration_utils -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 3,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\u001b[0m\n",
      "\u001b[31m}\n",
      "\u001b[0m\n",
      "\u001b[31m10/24/2019 15:30:41 - INFO - transformers.modeling_utils -   loading weights file /opt/ml/code/pretrained_models/bert-base-uncased/pytorch_model.bin\u001b[0m\n",
      "\u001b[31m10/24/2019 15:30:47 - INFO - transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\u001b[0m\n",
      "\u001b[31m10/24/2019 15:30:47 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\u001b[0m\n",
      "\u001b[31m/opt/ml/model/tensorboard\u001b[0m\n",
      "\u001b[31m10/24/2019 15:30:58 - INFO - root -   ***** Running training *****\u001b[0m\n",
      "\u001b[31m10/24/2019 15:30:58 - INFO - root -     Num examples = 134603\u001b[0m\n",
      "\u001b[31m10/24/2019 15:30:58 - INFO - root -     Num Epochs = 1\u001b[0m\n",
      "\u001b[31m10/24/2019 15:30:58 - INFO - root -     Total train batch size (w. parallel, distributed & accumulation) = 64\u001b[0m\n",
      "\u001b[31m10/24/2019 15:30:58 - INFO - root -     Gradient Accumulation steps = 8\u001b[0m\n",
      "\u001b[31m10/24/2019 15:30:58 - INFO - root -     Total optimization steps = 2103\u001b[0m\n",
      "\u001b[31m10/24/2019 15:36:47 - INFO - root -   Running evaluation\u001b[0m\n",
      "\u001b[31m10/24/2019 15:36:47 - INFO - root -     Num examples = 8973\u001b[0m\n",
      "\u001b[31m10/24/2019 15:36:47 - INFO - root -     Batch size = 16\u001b[0m\n",
      "\u001b[31m10/24/2019 15:37:32 - INFO - root -   eval_loss after step 300: 0.1461237840181791: \u001b[0m\n",
      "\u001b[31m10/24/2019 15:37:32 - INFO - root -   eval_accuracy after step 300: 0.9505182213306587: \u001b[0m\n",
      "\u001b[31m10/24/2019 15:37:32 - INFO - root -   lr after step 300: 2.4e-05\u001b[0m\n",
      "\u001b[31m10/24/2019 15:37:32 - INFO - root -   train_loss after step 300: 0.422031811773777\u001b[0m\n",
      "\u001b[31m10/24/2019 15:43:20 - INFO - root -   Running evaluation\u001b[0m\n",
      "\u001b[31m10/24/2019 15:43:20 - INFO - root -     Num examples = 8973\u001b[0m\n",
      "\u001b[31m10/24/2019 15:43:20 - INFO - root -     Batch size = 16\u001b[0m\n",
      "\u001b[31m10/24/2019 15:44:05 - INFO - root -   eval_loss after step 600: 0.10167158831993314: \u001b[0m\n",
      "\u001b[31m10/24/2019 15:44:05 - INFO - root -   eval_accuracy after step 600: 0.966677811211412: \u001b[0m\n",
      "\u001b[31m10/24/2019 15:44:05 - INFO - root -   lr after step 600: 3.961713806638841e-05\u001b[0m\n",
      "\u001b[31m10/24/2019 15:44:05 - INFO - root -   train_loss after step 600: 0.12843206399741272\u001b[0m\n",
      "\u001b[31m10/24/2019 15:49:51 - INFO - root -   Running evaluation\u001b[0m\n",
      "\u001b[31m10/24/2019 15:49:51 - INFO - root -     Num examples = 8973\u001b[0m\n",
      "\u001b[31m10/24/2019 15:49:51 - INFO - root -     Batch size = 16\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m10/24/2019 15:50:36 - INFO - root -   eval_loss after step 900: 0.10492015442746208: \u001b[0m\n",
      "\u001b[31m10/24/2019 15:50:36 - INFO - root -   eval_accuracy after step 900: 0.964783238604703: \u001b[0m\n",
      "\u001b[31m10/24/2019 15:50:36 - INFO - root -   lr after step 900: 3.416290737724918e-05\u001b[0m\n",
      "\u001b[31m10/24/2019 15:50:36 - INFO - root -   train_loss after step 900: 0.11460865293319027\u001b[0m\n",
      "\u001b[31m10/24/2019 15:56:22 - INFO - root -   Running evaluation\u001b[0m\n",
      "\u001b[31m10/24/2019 15:56:22 - INFO - root -     Num examples = 8973\u001b[0m\n",
      "\u001b[31m10/24/2019 15:56:22 - INFO - root -     Batch size = 16\u001b[0m\n",
      "\u001b[31m10/24/2019 15:57:07 - INFO - root -   eval_loss after step 1200: 0.08611540489044844: \u001b[0m\n",
      "\u001b[31m10/24/2019 15:57:07 - INFO - root -   eval_accuracy after step 1200: 0.9696868382926558: \u001b[0m\n",
      "\u001b[31m10/24/2019 15:57:07 - INFO - root -   lr after step 1200: 2.395225026408395e-05\u001b[0m\n",
      "\u001b[31m10/24/2019 15:57:07 - INFO - root -   train_loss after step 1200: 0.10511528893373906\u001b[0m\n",
      "\u001b[31m10/24/2019 16:02:53 - INFO - root -   Running evaluation\u001b[0m\n",
      "\u001b[31m10/24/2019 16:02:53 - INFO - root -     Num examples = 8973\u001b[0m\n",
      "\u001b[31m10/24/2019 16:02:53 - INFO - root -     Batch size = 16\u001b[0m\n",
      "\u001b[31m10/24/2019 16:03:38 - INFO - root -   eval_loss after step 1500: 0.09090780927973954: \u001b[0m\n",
      "\u001b[31m10/24/2019 16:03:38 - INFO - root -   eval_accuracy after step 1500: 0.9702440655299231: \u001b[0m\n",
      "\u001b[31m10/24/2019 16:03:38 - INFO - root -   lr after step 1500: 1.2414281809417607e-05\u001b[0m\n",
      "\u001b[31m10/24/2019 16:03:38 - INFO - root -   train_loss after step 1500: 0.09477109386275212\u001b[0m\n",
      "\u001b[31m10/24/2019 16:09:24 - INFO - root -   Running evaluation\u001b[0m\n",
      "\u001b[31m10/24/2019 16:09:24 - INFO - root -     Num examples = 8973\u001b[0m\n",
      "\u001b[31m10/24/2019 16:09:24 - INFO - root -     Batch size = 16\u001b[0m\n",
      "\u001b[31m10/24/2019 16:10:09 - INFO - root -   eval_loss after step 1800: 0.07946290863418883: \u001b[0m\n",
      "\u001b[31m10/24/2019 16:10:09 - INFO - root -   eval_accuracy after step 1800: 0.9726958653738995: \u001b[0m\n",
      "\u001b[31m10/24/2019 16:10:09 - INFO - root -   lr after step 1800: 3.4238771766300927e-06\u001b[0m\n",
      "\u001b[31m10/24/2019 16:10:09 - INFO - root -   train_loss after step 1800: 0.0852196062511454\u001b[0m\n",
      "\u001b[31m10/24/2019 16:15:55 - INFO - root -   Running evaluation\u001b[0m\n",
      "\u001b[31m10/24/2019 16:15:55 - INFO - root -     Num examples = 8973\u001b[0m\n",
      "\u001b[31m10/24/2019 16:15:55 - INFO - root -     Batch size = 16\u001b[0m\n",
      "\u001b[31m10/24/2019 16:16:40 - INFO - root -   eval_loss after step 2100: 0.07814394063424193: \u001b[0m\n",
      "\u001b[31m10/24/2019 16:16:40 - INFO - root -   eval_accuracy after step 2100: 0.9729187562688064: \u001b[0m\n",
      "\u001b[31m10/24/2019 16:16:40 - INFO - root -   lr after step 2100: 3.45679765794138e-10\u001b[0m\n",
      "\u001b[31m10/24/2019 16:16:40 - INFO - root -   train_loss after step 2100: 0.08476837416489919\u001b[0m\n",
      "\u001b[31m10/24/2019 16:16:44 - INFO - root -   Running evaluation\u001b[0m\n",
      "\u001b[31m10/24/2019 16:16:44 - INFO - root -     Num examples = 8973\u001b[0m\n",
      "\u001b[31m10/24/2019 16:16:44 - INFO - root -     Batch size = 16\u001b[0m\n",
      "\n",
      "2019-10-24 16:17:32 Uploading - Uploading generated training model\u001b[31m10/24/2019 16:17:29 - INFO - root -   eval_loss after epoch 1: 0.07814393801790614: \u001b[0m\n",
      "\u001b[31m10/24/2019 16:17:29 - INFO - root -   eval_accuracy after epoch 1: 0.9729187562688064: \u001b[0m\n",
      "\u001b[31m10/24/2019 16:17:29 - INFO - root -   lr after epoch 1: 0.0\u001b[0m\n",
      "\u001b[31m10/24/2019 16:17:29 - INFO - root -   train_loss after epoch 1: 0.14772364824288003\u001b[0m\n",
      "\u001b[31m10/24/2019 16:17:29 - INFO - root -   \n",
      "\u001b[0m\n",
      "\u001b[31m10/24/2019 16:17:29 - INFO - transformers.configuration_utils -   Configuration saved in /opt/ml/model/model_out/config.json\u001b[0m\n",
      "\u001b[31m10/24/2019 16:17:29 - INFO - transformers.modeling_utils -   Model weights saved in /opt/ml/model/model_out/pytorch_model.bin\u001b[0m\n",
      "\n",
      "2019-10-24 16:18:33 Completed - Training job completed\n",
      "Training seconds: 3171\n",
      "Billable seconds: 3171\n"
     ]
    }
   ],
   "source": [
    "# Create the estimator\n",
    "estimator = sagemaker.estimator.Estimator(image,                                # ECR image arn\n",
    "                                          role,                                 # execution role\n",
    "                                          train_instance_count=1,               # no. of sagemaker instances\n",
    "                                          train_instance_type='ml.p3.2xlarge',  # instance type\n",
    "                                          output_path=output_path,              # output path to store model outputs\n",
    "                                          base_job_name='bert-sentiment',       # job name prefix\n",
    "                                          hyperparameters=hyperparameters,      # hyperparamters object\n",
    "                                          sagemaker_session=session             # session\n",
    "                                         )\n",
    "\n",
    "# Launch instance and start training\n",
    "estimator.fit(data_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using already existing model: bert-sentiment-2019-10-24-15-23-27-102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------------------------------------------!CPU times: user 777 ms, sys: 44.3 ms, total: 821 ms\n",
      "Wall time: 11min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from time import gmtime, strftime\n",
    "\n",
    "endpoint_name = 'bert-sentiment-' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "\n",
    "predictor = estimator.deploy(initial_instance_count = 1, \n",
    "                             instance_type = 'ml.t2.large', \n",
    "                             endpoint_name = endpoint_name,\n",
    "                             serializer=json_serializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'[[\"mixed\", 0.9535662531852722], [\"neg\", 0.02639363519847393], [\"pos\", 0.020040083676576614]]'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "payload = json.dumps({\"text\":\"The food was nice, element of improvement on the preparation of the ribs should be grilled. \\\n",
    "Please invest in a flat top griller. Use a different bbq sauce for the chicken wings and  ribs. \\\n",
    "Overall service from Andries was great. \"})\n",
    "\n",
    "print(predictor.predict(payload))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single prediction with invoke endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['mixed', 0.9535662531852722], ['neg', 0.02639363519847393], ['pos', 0.020040083676576614]]\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.content_types import CONTENT_TYPE_JSON\n",
    "\n",
    "client = boto3.client('sagemaker-runtime')\n",
    "\n",
    "content_type=CONTENT_TYPE_JSON\n",
    "accept='application/json'\n",
    "\n",
    "response = client.invoke_endpoint(EndpointName = endpoint_name,\n",
    "                                  ContentType = content_type,\n",
    "                                  Accept=accept,\n",
    "                                  Body=payload)\n",
    "\n",
    "\n",
    "probas = json.loads(response['Body'].read().decode())\n",
    "print(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction is: ['mixed', 0.9535662531852722]\n"
     ]
    }
   ],
   "source": [
    "# function to get highest probability from three likelihoods\n",
    "# for single responses\n",
    "\n",
    "def get_prediction(probas):\n",
    "    return max(probas, key=lambda item:item[1])\n",
    "\n",
    "pred = get_prediction(probas)\n",
    "print('Prediction is: {}'.format(pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple predictions with invoke endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['mixed', 0.9535662531852722], ['neg', 0.02639363519847393], ['pos', 0.020040083676576614]], [['neg', 0.995301365852356], ['mixed', 0.004171039909124374], ['pos', 0.0005276606534607708]]]\n"
     ]
    }
   ],
   "source": [
    "reviews = [\"The food was nice, element of improvement on the preparation of the ribs should be grilled. \\\n",
    "            Please invest in a flat top griller. Use a different bbq sauce for the chicken wings and  ribs. \\\n",
    "            Overall service from Andries was great. \",\n",
    "           \n",
    "           \"They delivered lamb chops that were off. The chops were smelly that I threw up. I took them back \\\n",
    "            and they told me that it's the smell of lamb; I mean, really, I've eaten lamb before it didn't smelled \\\n",
    "            off and never tasted like that. This is unacceptable, I couldn't have gotten sick.\\\n",
    "            Food inspectors need to check it out \"]\n",
    "\n",
    "payloads = [{\"text\" : review} for review in reviews]\n",
    "\n",
    "content_type=CONTENT_TYPE_JSON\n",
    "accept='application/json'\n",
    "\n",
    "probas = []\n",
    "\n",
    "# I am using a loop as a work around for batch predictions, as invoke \n",
    "# endpoint only manages one request at a time. \n",
    "for payload in payloads:\n",
    "    response = client.invoke_endpoint(EndpointName = endpoint_name,\n",
    "                                      ContentType = content_type,\n",
    "                                      Accept=accept,\n",
    "                                      Body=json.dumps(payload))\n",
    "    \n",
    "    result = json.loads(response['Body'].read().decode())\n",
    "    probas.append(result)\n",
    "    \n",
    "print(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions are: [[['mixed', 0.9535662531852722], ['neg', 0.995301365852356]]]\n"
     ]
    }
   ],
   "source": [
    "# function to get highest probability from three likelihoods\n",
    "# for multiple responses\n",
    "\n",
    "def get_predictions(probas):\n",
    "    return [max(prob, key=lambda item:item[1]) for prob in probas]\n",
    "\n",
    "preds = get_predictions(probas)\n",
    "print('Predictions are: {}'.format(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '1892ba70-9475-46a6-85f1-4df60f1cf2ea',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '1892ba70-9475-46a6-85f1-4df60f1cf2ea',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '0',\n",
       "   'date': 'Thu, 24 Oct 2019 22:58:02 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_client = session.boto_session.client('sagemaker')\n",
    "sm_client.delete_endpoint(EndpointName=endpoint_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
